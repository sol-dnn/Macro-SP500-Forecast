from src.pipeline import ModelPipeline
import pandas as pd

# 1) Load your saved pipeline
mp = ModelPipeline.load_model("artifacts/model.joblib")

# 2) Load or construct the DataFrame that has all transformations applied:
# Â  Â For example, if you precomputed transformations offline:
df_scoring = pd.read_parquet("data/processed/scoring_dataset.parquet")

# 3) Define your CV configuration exactly as in training
cv_conf = {
Â  Â  "n_splits": 5,
Â  Â  "embargo": 2,
Â  Â  "purge": True,
Â  Â  # â€¦etc, matching your PurgedWalkForwardCV signatureâ€¦
}

# 4) Call apply_model on that DataFrame
results = mp.apply_model(
Â  Â  df_model=df_scoring,
Â  Â  cv_conf=cv_conf,
Â  Â  target="y", Â  Â  Â  Â  Â  Â  Â  Â # your target column name
Â  Â  features=[ Â  Â  Â  Â  Â  Â  Â  Â  Â # list exactly the feature columns the pipeline uses
Â  Â  Â  Â  "feat1", "feat2", "feat3", â€¦
Â  Â  ],
Â  Â  split_stage="S1", Â  Â  Â  Â  Â  # or "S2" if you want that stage
Â  Â  get_feature_analysis=False Â # turn on if you also want importances/PCA
)

# 5) Inspect the outputs
df_preds Â  Â  = results["val_preds"]
ml_score Â  Â  = results["ml_superiority_mean"]
mae_score Â  Â = results["mae_mean"]

print("OOS predictions shape:", df_preds.shape)
print("ML superiority:", ml_score)
print("MAE:", mae_score)


# S&P 500 Forecasting Using Macro-Financial Variables

## Overview
This project leverages **machine learning** techniques to forecast the **weekly log returns** of the **S&P 500** using a dataset of macro-financial variables spanning over 20 years as part of **AI for Alpha**'s data challenge. The project was implemented using an **Object-Oriented Programming (OOP)** approach for better modularity and maintainability.

## Features
- **Exploratory Data Analysis:** ..
- **Data Preprocessing:** Handles missing values, outliers, and feature scaling.
- **Feature Selection:** Uses PCA, correlation analysis with bonferonni correction and permutation importance.
- **Modeling:** Implements a forecaster including time series split, ....
- **Hyperparameter Tuning:** Uses randomized search for optimal model performance.
- **Evaluation Metrics:** Custom scoring function combining RMSE and Directional Accuracy (DA).

## Installation
To set up the environment, install the required dependencies:

```bash
pip install -r requirements.txt
```

## Project Structure
```plaintext
ðŸ“‚ Macro-SP500-Forecast
â”‚â”€â”€ ðŸ“‚ data                    # Raw datasets (S&P Daily Close Price and Macro-Financial Features)
â”‚â”€â”€ ðŸ“‚ src                     # Source code
â”‚   â”‚â”€â”€ processor.py           # Preprocessing module
â”‚   â”‚â”€â”€ EDA.ipynb              # Exploratory Data Analysis
â”‚   â”‚â”€â”€ skew_transformer.py    # Skew Transforer module
â”‚   â”‚â”€â”€ forecaster.py          # Machine learning models
â”‚   â”‚â”€â”€ arimaforecaster.py     # Autoregressive models
â”‚   â”‚â”€â”€ main.ipynb             # Main script to run the forecasting
â”‚â”€â”€ prpoject_report            # Written Project Report
â”‚â”€â”€ README.md                  # Documentation
```

## License
MIT License.

---
### Author
Solal Danan
