import joblib
import pandas as pd
from sklearn.base import clone
from src.cv import PurgedWalkForwardCV
from sklearn.inspection import permutation_importance
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from src.utils import compute_ml_superiority, compute_mae
import os
from datetime import datetime

class ModelPipeline:
Â  Â  """
Â  Â  Wrapper for scikit-learn pipeline with support for purged walk-forward validation.

Â  Â  Available methods:
Â  Â  Â  - load_model / save_model: persist and reload trained pipelines
Â  Â  Â  - apply_model: train and predict across multiple splits (S1 or S2)
Â  Â  Â  - analyze_features: compute MDI, MDA, PCA metrics for a given split
Â  Â  """
Â  Â  # Default directory to persist models
Â  Â  DEFAULT_MODEL_DIR = "artifacts"

Â  Â  def __init__(self, pipeline=None):
Â  Â  Â  Â  self.pipeline = pipeline

Â  Â  @classmethod
Â  Â  def load_model(cls, path: str) -> "ModelPipeline":
Â  Â  Â  Â  # Load a previously saved pipeline from disk and return a ModelPipeline instance.
Â  Â  Â  Â  # This allows scoring without retraining by restoring preprocessing and model state.
Â  Â  Â  Â  pipe = joblib.load(path)
Â  Â  Â  Â  return cls(pipeline=pipe)

Â  Â  def save_model(self, path: str = None):
Â  Â  Â  Â  """
Â  Â  Â  Â  Save the current scikit-learn pipeline to disk using joblib.

Â  Â  Â  Â  If no path is provided, saves to artifacts/model_<timestamp>.joblib by default,
Â  Â  Â  Â  preserving previous versions. To use a custom filename or directory,
Â  Â  Â  Â  supply an explicit path argument.
Â  Â  Â  Â  """
Â  Â  Â  Â  if self.pipeline is None:
Â  Â  Â  Â  Â  Â  raise ValueError("No pipeline loaded to save.")

Â  Â  Â  Â  # Ensure default directory exists
Â  Â  Â  Â  os.makedirs(self.DEFAULT_MODEL_DIR, exist_ok=True)

Â  Â  Â  Â  if path is None:
Â  Â  Â  Â  Â  Â  timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
Â  Â  Â  Â  Â  Â  filename = f"model_{timestamp}.joblib"
Â  Â  Â  Â  Â  Â  path = os.path.join(self.DEFAULT_MODEL_DIR, filename)

Â  Â  Â  Â  # Persist the pipeline
Â  Â  Â  Â  joblib.dump(self.pipeline, path)
Â  Â  Â  Â  return path

Â  Â  def apply_model(
Â  Â  Â  Â  self,
Â  Â  Â  Â  df_model: pd.DataFrame,
Â  Â  Â  Â  cv_conf: dict,
Â  Â  Â  Â  target: str,
Â  Â  Â  Â  features: list,
Â  Â  Â  Â  split_stage: str = 'S1',
Â  Â  Â  Â  get_feature_analysis: bool = False
Â  Â  ) -> dict:
Â  Â  Â  Â  """
Â  Â  Â  Â  Apply purged walk-forward CV across splits, returning predictions and scores.

Â  Â  Â  Â  Args:
Â  Â  Â  Â  Â  Â  df_model: DataFrame with MultiIndex (date, instrument)
Â  Â  Â  Â  Â  Â  cv_conf: dict parameters for PurgedWalkForwardCV
Â  Â  Â  Â  Â  Â  target: name of target column
Â  Â  Â  Â  Â  Â  features: list of feature column names
Â  Â  Â  Â  Â  Â  split_stage: 'S1' or 'S2' to choose split set
Â  Â  Â  Â  Â  Â  get_feature_analysis: if True, return MDI/MDA/PCA per split

Â  Â  Â  Â  Returns:
Â  Â  Â  Â  Â  Â  dict containing:
Â  Â  Â  Â  Â  Â  Â  - 'val_preds': concatenated validation predictions
Â  Â  Â  Â  Â  Â  Â  - 'ml_superiority_mean': average ML superiority score
Â  Â  Â  Â  Â  Â  Â  - 'mae_mean': average MAE
Â  Â  Â  Â  Â  Â  Â  - optional 'mdi','mda','pca' DataFrames
Â  Â  Â  Â  """
Â  Â  Â  Â  all_pred = []
Â  Â  Â  Â  feat_info = {'mdi': [], 'mda': [], 'pca': []}

Â  Â  Â  Â  pcv = PurgedWalkForwardCV(**cv_conf)
Â  Â  Â  Â  splits = pcv.get_splits()[split_stage]

Â  Â  Â  Â  for split_id, split in enumerate(splits, start=1):
Â  Â  Â  Â  Â  Â  train_idx, test_idx = split['train_idx'], split['test_idx']
Â  Â  Â  Â  Â  Â  df_train = df_model[df_model.index.get_level_values('date').isin(train_idx)]
Â  Â  Â  Â  Â  Â  df_test Â = df_model[df_model.index.get_level_values('date').isin(test_idx)]

Â  Â  Â  Â  Â  Â  X_train, y_train = df_train[features], df_train[target]
Â  Â  Â  Â  Â  Â  X_test, Â y_test Â = df_test[features], Â df_test[target]

Â  Â  Â  Â  Â  Â  pipe = clone(self.pipeline)
Â  Â  Â  Â  Â  Â  pipe.fit(X_train, y_train)
Â  Â  Â  Â  Â  Â  y_pred = pipe.predict(X_test)

Â  Â  Â  Â  Â  Â  df_tmp = df_test.copy()
Â  Â  Â  Â  Â  Â  df_tmp['y_true'] = y_test.values
Â  Â  Â  Â  Â  Â  df_tmp['y_pred'] = y_pred
Â  Â  Â  Â  Â  Â  all_pred.append(df_tmp)

Â  Â  Â  Â  Â  Â  if get_feature_analysis:
Â  Â  Â  Â  Â  Â  Â  Â  info = self.analyze_features(pipe, X_test, y_test, split_id, features)
Â  Â  Â  Â  Â  Â  Â  Â  for k, df_info in info.items():
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  feat_info[k].append(df_info)

Â  Â  Â  Â  df_preds = pd.concat(all_pred).sort_index()
Â  Â  Â  Â  df_preds = df_preds.drop_duplicates(
Â  Â  Â  Â  Â  Â  subset=['date', df_preds.index.get_level_values(1).name], keep='last'
Â  Â  Â  Â  )

Â  Â  Â  Â  ml_score Â = compute_ml_superiority(df_preds, pred_col='y_pred')
Â  Â  Â  Â  mae_score = compute_mae(df_preds['y_true'], df_preds['y_pred'])

Â  Â  Â  Â  results = {
Â  Â  Â  Â  Â  Â  'val_preds': df_preds,
Â  Â  Â  Â  Â  Â  'ml_superiority_mean': ml_score,
Â  Â  Â  Â  Â  Â  'mae_mean': mae_score
Â  Â  Â  Â  }
Â  Â  Â  Â  if get_feature_analysis:
Â  Â  Â  Â  Â  Â  results.update({k: pd.concat(v) for k, v in feat_info.items()})
Â  Â  Â  Â  return results

Â  Â  def analyze_features(
Â  Â  Â  Â  self,
Â  Â  Â  Â  fitted_pipe,
Â  Â  Â  Â  X_test: pd.DataFrame,
Â  Â  Â  Â  y_test: pd.Series,
Â  Â  Â  Â  split_id: int,
Â  Â  Â  Â  feature_names: list
Â  Â  ) -> dict:
Â  Â  Â  Â  """
Â  Â  Â  Â  Analyze feature importances (MDI, MDA) and PCA for a single split.

Â  Â  Â  Â  Returns a dict of DataFrames for keys 'mdi', 'mda', and 'pca'.
Â  Â  Â  Â  """
Â  Â  Â  Â  names = fitted_pipe.named_steps['preprocessor'].get_feature_names_out()
Â  Â  Â  Â  info = {}

Â  Â  Â  Â  # MDI (Mean Decrease in Impurity) for tree-based models
Â  Â  Â  Â  est = fitted_pipe.named_steps.get('estimator', fitted_pipe)
Â  Â  Â  Â  if hasattr(est, 'feature_importances_'):
Â  Â  Â  Â  Â  Â  mdi_df = pd.DataFrame({
Â  Â  Â  Â  Â  Â  Â  Â  'feature': names,
Â  Â  Â  Â  Â  Â  Â  Â  'importance': est.feature_importances_,
Â  Â  Â  Â  Â  Â  Â  Â  'split': split_id
Â  Â  Â  Â  Â  Â  })
Â  Â  Â  Â  Â  Â  info['mdi'] = mdi_df

Â  Â  Â  Â  # MDA (Mean Decrease in Accuracy) via permutation importance
Â  Â  Â  Â  perm = permutation_importance(
Â  Â  Â  Â  Â  Â  fitted_pipe, X_test, y_test,
Â  Â  Â  Â  Â  Â  n_repeats=10, scoring='neg_mean_absolute_error', random_state=42, n_jobs=-1
Â  Â  Â  Â  )
Â  Â  Â  Â  mda_df = pd.DataFrame({
Â  Â  Â  Â  Â  Â  'feature': names,
Â  Â  Â  Â  Â  Â  'importance': perm.importances_mean,
Â  Â  Â  Â  Â  Â  'split': split_id
Â  Â  Â  Â  })
Â  Â  Â  Â  info['mda'] = mda_df

Â  Â  Â  Â  # PCA explained variance per feature
Â  Â  Â  Â  X_proc = fitted_pipe.named_steps['preprocessor'].transform(X_test)
Â  Â  Â  Â  Z = StandardScaler().fit_transform(X_proc)
Â  Â  Â  Â  pca = PCA(n_components=len(names)).fit(Z)
Â  Â  Â  Â  pca_df = pd.DataFrame({
Â  Â  Â  Â  Â  Â  Â  Â  'feature': names,
Â  Â  Â  Â  Â  Â  Â  Â  'explained_variance': pca.explained_variance_,
Â  Â  Â  Â  Â  Â  Â  Â  'split': split_id
Â  Â  Â  Â  })
Â  Â  Â  Â  info['pca'] = pca_df

Â  Â  Â  Â  return info



from src.pipeline import ModelPipeline
import pandas as pd

# 1) Load your saved pipeline
mp = ModelPipeline.load_model("artifacts/model.joblib")

# 2) Load or construct the DataFrame that has all transformations applied:
# Â  Â For example, if you precomputed transformations offline:
df_scoring = pd.read_parquet("data/processed/scoring_dataset.parquet")

# 3) Define your CV configuration exactly as in training
cv_conf = {
Â  Â  "n_splits": 5,
Â  Â  "embargo": 2,
Â  Â  "purge": True,
Â  Â  # â€¦etc, matching your PurgedWalkForwardCV signatureâ€¦
}

# 4) Call apply_model on that DataFrame
results = mp.apply_model(
Â  Â  df_model=df_scoring,
Â  Â  cv_conf=cv_conf,
Â  Â  target="y", Â  Â  Â  Â  Â  Â  Â  Â # your target column name
Â  Â  features=[ Â  Â  Â  Â  Â  Â  Â  Â  Â # list exactly the feature columns the pipeline uses
Â  Â  Â  Â  "feat1", "feat2", "feat3", â€¦
Â  Â  ],
Â  Â  split_stage="S1", Â  Â  Â  Â  Â  # or "S2" if you want that stage
Â  Â  get_feature_analysis=False Â # turn on if you also want importances/PCA
)

# 5) Inspect the outputs
df_preds Â  Â  = results["val_preds"]
ml_score Â  Â  = results["ml_superiority_mean"]
mae_score Â  Â = results["mae_mean"]

print("OOS predictions shape:", df_preds.shape)
print("ML superiority:", ml_score)
print("MAE:", mae_score)





# S&P 500 Forecasting Using Macro-Financial Variables

## Overview
This project leverages **machine learning** techniques to forecast the **weekly log returns** of the **S&P 500** using a dataset of macro-financial variables spanning over 20 years as part of **AI for Alpha**'s data challenge. The project was implemented using an **Object-Oriented Programming (OOP)** approach for better modularity and maintainability.

## Features
- **Exploratory Data Analysis:** ..
- **Data Preprocessing:** Handles missing values, outliers, and feature scaling.
- **Feature Selection:** Uses PCA, correlation analysis with bonferonni correction and permutation importance.
- **Modeling:** Implements a forecaster including time series split, ....
- **Hyperparameter Tuning:** Uses randomized search for optimal model performance.
- **Evaluation Metrics:** Custom scoring function combining RMSE and Directional Accuracy (DA).

## Installation
To set up the environment, install the required dependencies:

```bash
pip install -r requirements.txt
```

## Project Structure
```plaintext
ðŸ“‚ Macro-SP500-Forecast
â”‚â”€â”€ ðŸ“‚ data                    # Raw datasets (S&P Daily Close Price and Macro-Financial Features)
â”‚â”€â”€ ðŸ“‚ src                     # Source code
â”‚   â”‚â”€â”€ processor.py           # Preprocessing module
â”‚   â”‚â”€â”€ EDA.ipynb              # Exploratory Data Analysis
â”‚   â”‚â”€â”€ skew_transformer.py    # Skew Transforer module
â”‚   â”‚â”€â”€ forecaster.py          # Machine learning models
â”‚   â”‚â”€â”€ arimaforecaster.py     # Autoregressive models
â”‚   â”‚â”€â”€ main.ipynb             # Main script to run the forecasting
â”‚â”€â”€ prpoject_report            # Written Project Report
â”‚â”€â”€ README.md                  # Documentation
```

## License
MIT License.

---
### Author
Solal Danan
